{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Chinese-Text-Classification-Pytorch.ipynb",
      "provenance": [],
      "mount_file_id": "1izYNLq2z-nj_ztSliRit9Rf0tdniY7Of",
      "authorship_tag": "ABX9TyMEALC/G19U9j5r2ES32kd3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinerayLu/NLP-First-Class/blob/main/02_Chinese_Text_Classification_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0GPHY2U2F_5",
        "outputId": "9a4d4ef5-e3fb-4f6e-eff4-6c984113c1ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\r\u001b[K     |█                               | 10kB 20.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 27.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 22.5MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 17.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102kB 11.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 11.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122kB 11.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133kB 11.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143kB 11.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 11.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163kB 11.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174kB 11.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 11.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194kB 11.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204kB 11.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215kB 11.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225kB 11.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 235kB 11.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245kB 11.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 256kB 11.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266kB 11.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 276kB 11.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286kB 11.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 296kB 11.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 307kB 11.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (50.3.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb_pv_EizZSI",
        "outputId": "aa1600f9-941f-4384-8b17-b2f535a4d14e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "!git clone https://github.com/649453932/Chinese-Text-Classification-Pytorch.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Chinese-Text-Classification-Pytorch'...\n",
            "remote: Enumerating objects: 215, done.\u001b[K\n",
            "remote: Total 215 (delta 0), reused 0 (delta 0), pack-reused 215\u001b[K\n",
            "Receiving objects: 100% (215/215), 42.09 MiB | 38.10 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57DT31vcAG5Z",
        "outputId": "fc79c2ab-ce81-429a-9a27-088c7c677451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Oct 28 06:58:46 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14oj18EfAloM"
      },
      "source": [
        "!mv Chinese-Text-Classification-Pytorch/* ."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBqzYfOxAvak",
        "outputId": "574c7457-c68d-479b-de9b-5056b3d5ef59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run.py --model DPCNN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Vocab size: 4762\n",
            "180000it [00:02, 84966.75it/s]\n",
            "10000it [00:00, 92827.20it/s]\n",
            "10000it [00:00, 48186.74it/s]\n",
            "Time usage: 0:00:02\n",
            "<bound method Module.parameters of Model(\n",
            "  (embedding): Embedding(4762, 300)\n",
            "  (conv_region): Conv2d(1, 250, kernel_size=(3, 300), stride=(1, 1))\n",
            "  (conv): Conv2d(250, 250, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (max_pool): MaxPool2d(kernel_size=(3, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (padding1): ZeroPad2d(padding=(0, 0, 1, 1), value=0.0)\n",
            "  (padding2): ZeroPad2d(padding=(0, 0, 0, 1), value=0.0)\n",
            "  (relu): ReLU()\n",
            "  (fc): Linear(in_features=250, out_features=10, bias=True)\n",
            ")>\n",
            "Epoch [1/20]\n",
            "Iter:      0,  Train Loss:   2.3,  Train Acc: 10.94%,  Val Loss:   2.8,  Val Acc:  8.06%,  Time: 0:00:00 *\n",
            "Iter:    100,  Train Loss:  0.73,  Train Acc: 74.22%,  Val Loss:  0.76,  Val Acc: 75.53%,  Time: 0:00:03 *\n",
            "Iter:    200,  Train Loss:   0.7,  Train Acc: 77.34%,  Val Loss:   0.6,  Val Acc: 80.76%,  Time: 0:00:05 *\n",
            "Iter:    300,  Train Loss:  0.45,  Train Acc: 88.28%,  Val Loss:  0.52,  Val Acc: 83.08%,  Time: 0:00:07 *\n",
            "Iter:    400,  Train Loss:  0.58,  Train Acc: 81.25%,  Val Loss:  0.51,  Val Acc: 84.13%,  Time: 0:00:09 *\n",
            "Iter:    500,  Train Loss:   0.4,  Train Acc: 86.72%,  Val Loss:  0.43,  Val Acc: 86.33%,  Time: 0:00:11 *\n",
            "Iter:    600,  Train Loss:  0.43,  Train Acc: 86.72%,  Val Loss:  0.46,  Val Acc: 85.41%,  Time: 0:00:13 \n",
            "Iter:    700,  Train Loss:  0.44,  Train Acc: 85.16%,  Val Loss:  0.45,  Val Acc: 85.21%,  Time: 0:00:15 \n",
            "Iter:    800,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.39,  Val Acc: 87.50%,  Time: 0:00:17 *\n",
            "Iter:    900,  Train Loss:  0.37,  Train Acc: 86.72%,  Val Loss:  0.37,  Val Acc: 88.09%,  Time: 0:00:20 *\n",
            "Iter:   1000,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:  0.37,  Val Acc: 87.94%,  Time: 0:00:22 *\n",
            "Iter:   1100,  Train Loss:  0.35,  Train Acc: 89.06%,  Val Loss:  0.39,  Val Acc: 87.27%,  Time: 0:00:24 \n",
            "Iter:   1200,  Train Loss:  0.35,  Train Acc: 90.62%,  Val Loss:  0.37,  Val Acc: 88.16%,  Time: 0:00:26 \n",
            "Iter:   1300,  Train Loss:  0.39,  Train Acc: 87.50%,  Val Loss:  0.34,  Val Acc: 89.10%,  Time: 0:00:28 *\n",
            "Iter:   1400,  Train Loss:   0.4,  Train Acc: 89.84%,  Val Loss:  0.35,  Val Acc: 88.41%,  Time: 0:00:31 \n",
            "Epoch [2/20]\n",
            "Iter:   1500,  Train Loss:  0.35,  Train Acc: 88.28%,  Val Loss:  0.34,  Val Acc: 89.24%,  Time: 0:00:33 *\n",
            "Iter:   1600,  Train Loss:  0.32,  Train Acc: 92.19%,  Val Loss:  0.36,  Val Acc: 88.56%,  Time: 0:00:35 \n",
            "Iter:   1700,  Train Loss:  0.37,  Train Acc: 88.28%,  Val Loss:  0.34,  Val Acc: 89.29%,  Time: 0:00:37 \n",
            "Iter:   1800,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.34,  Val Acc: 89.13%,  Time: 0:00:40 \n",
            "Iter:   1900,  Train Loss:  0.29,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 89.90%,  Time: 0:00:42 *\n",
            "Iter:   2000,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 90.17%,  Time: 0:00:44 *\n",
            "Iter:   2100,  Train Loss:   0.3,  Train Acc: 89.06%,  Val Loss:   0.3,  Val Acc: 90.29%,  Time: 0:00:46 *\n",
            "Iter:   2200,  Train Loss:  0.23,  Train Acc: 93.75%,  Val Loss:  0.32,  Val Acc: 90.15%,  Time: 0:00:49 \n",
            "Iter:   2300,  Train Loss:  0.21,  Train Acc: 94.53%,  Val Loss:  0.31,  Val Acc: 89.93%,  Time: 0:00:51 \n",
            "Iter:   2400,  Train Loss:  0.21,  Train Acc: 91.41%,  Val Loss:  0.37,  Val Acc: 88.50%,  Time: 0:00:53 \n",
            "Iter:   2500,  Train Loss:   0.2,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.52%,  Time: 0:00:55 \n",
            "Iter:   2600,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 90.11%,  Time: 0:00:57 \n",
            "Iter:   2700,  Train Loss:  0.22,  Train Acc: 93.75%,  Val Loss:  0.31,  Val Acc: 90.39%,  Time: 0:00:59 \n",
            "Iter:   2800,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 89.76%,  Time: 0:01:02 \n",
            "Epoch [3/20]\n",
            "Iter:   2900,  Train Loss:  0.32,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 90.06%,  Time: 0:01:04 \n",
            "Iter:   3000,  Train Loss:  0.21,  Train Acc: 92.97%,  Val Loss:   0.3,  Val Acc: 90.71%,  Time: 0:01:06 *\n",
            "Iter:   3100,  Train Loss:   0.2,  Train Acc: 94.53%,  Val Loss:   0.3,  Val Acc: 90.45%,  Time: 0:01:08 \n",
            "Iter:   3200,  Train Loss:  0.43,  Train Acc: 92.19%,  Val Loss:  0.34,  Val Acc: 89.74%,  Time: 0:01:10 \n",
            "Iter:   3300,  Train Loss:  0.22,  Train Acc: 91.41%,  Val Loss:   0.3,  Val Acc: 90.71%,  Time: 0:01:12 \n",
            "Iter:   3400,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:   0.3,  Val Acc: 90.66%,  Time: 0:01:15 \n",
            "Iter:   3500,  Train Loss:  0.17,  Train Acc: 96.09%,  Val Loss:  0.34,  Val Acc: 89.90%,  Time: 0:01:17 \n",
            "Iter:   3600,  Train Loss: 0.097,  Train Acc: 97.66%,  Val Loss:  0.31,  Val Acc: 90.72%,  Time: 0:01:19 \n",
            "Iter:   3700,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 90.41%,  Time: 0:01:21 \n",
            "Iter:   3800,  Train Loss:  0.28,  Train Acc: 88.28%,  Val Loss:  0.31,  Val Acc: 90.48%,  Time: 0:01:23 \n",
            "Iter:   3900,  Train Loss:  0.34,  Train Acc: 89.06%,  Val Loss:  0.32,  Val Acc: 90.23%,  Time: 0:01:25 \n",
            "Iter:   4000,  Train Loss:  0.13,  Train Acc: 94.53%,  Val Loss:  0.33,  Val Acc: 89.72%,  Time: 0:01:27 \n",
            "No optimization for a long time, auto-stopping...\n",
            "Test Loss:  0.28,  Test Acc: 90.89%\n",
            "Precision, Recall and F1-Score...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      finance     0.8956    0.9010    0.8983      1000\n",
            "       realty     0.8843    0.9480    0.9151      1000\n",
            "       stocks     0.8651    0.8080    0.8356      1000\n",
            "    education     0.9215    0.9630    0.9418      1000\n",
            "      science     0.8533    0.8670    0.8601      1000\n",
            "      society     0.9338    0.8890    0.9109      1000\n",
            "     politics     0.8993    0.8750    0.8870      1000\n",
            "       sports     0.9749    0.9710    0.9729      1000\n",
            "         game     0.9391    0.9260    0.9325      1000\n",
            "entertainment     0.9225    0.9410    0.9317      1000\n",
            "\n",
            "     accuracy                         0.9089     10000\n",
            "    macro avg     0.9090    0.9089    0.9086     10000\n",
            " weighted avg     0.9090    0.9089    0.9086     10000\n",
            "\n",
            "Confusion Matrix...\n",
            "[[901  24  45   6   7   6   7   2   1   1]\n",
            " [ 12 948  13   1   4   6   2   4   2   8]\n",
            " [ 66  37 808   6  41   2  30   1   8   1]\n",
            " [  1   3   0 963   4   8   6   1   2  12]\n",
            " [  4   6  32  14 867  14  20   0  30  13]\n",
            " [  3  23   2  21  11 889  25   3   3  20]\n",
            " [ 13  14  25  19  24  19 875   2   2   7]\n",
            " [  0   3   2   4   3   2   5 971   0  10]\n",
            " [  4   5   6   3  43   4   1   1 926   7]\n",
            " [  2   9   1   8  12   2   2  11  12 941]]\n",
            "Time usage: 0:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apD5IVLSBrV5",
        "outputId": "fb07f162-50db-44e4-f323-6c1d1fe7c4e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run.py --model FastText"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Vocab size: 4762\n",
            "180000it [00:07, 23291.23it/s]\n",
            "10000it [00:00, 26850.75it/s]\n",
            "10000it [00:00, 27743.74it/s]\n",
            "Time usage: 0:00:08\n",
            "<bound method Module.parameters of Model(\n",
            "  (embedding): Embedding(4762, 300, padding_idx=4761)\n",
            "  (embedding_ngram2): Embedding(250499, 300)\n",
            "  (embedding_ngram3): Embedding(250499, 300)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=900, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")>\n",
            "Epoch [1/20]\n",
            "Iter:      0,  Train Loss:   2.4,  Train Acc: 15.62%,  Val Loss:   2.3,  Val Acc:  9.37%,  Time: 0:00:03 *\n",
            "Iter:    100,  Train Loss:   1.1,  Train Acc: 62.50%,  Val Loss:   1.0,  Val Acc: 68.01%,  Time: 0:00:11 *\n",
            "Iter:    200,  Train Loss:   1.1,  Train Acc: 64.06%,  Val Loss:  0.75,  Val Acc: 76.63%,  Time: 0:00:20 *\n",
            "Iter:    300,  Train Loss:  0.71,  Train Acc: 73.44%,  Val Loss:  0.68,  Val Acc: 78.16%,  Time: 0:00:29 *\n",
            "Iter:    400,  Train Loss:  0.89,  Train Acc: 70.31%,  Val Loss:  0.67,  Val Acc: 77.42%,  Time: 0:00:44 *\n",
            "Iter:    500,  Train Loss:  0.66,  Train Acc: 80.47%,  Val Loss:  0.57,  Val Acc: 81.56%,  Time: 0:01:00 *\n",
            "Iter:    600,  Train Loss:   0.6,  Train Acc: 78.91%,  Val Loss:  0.54,  Val Acc: 82.58%,  Time: 0:01:16 *\n",
            "Iter:    700,  Train Loss:  0.76,  Train Acc: 71.88%,  Val Loss:  0.53,  Val Acc: 83.01%,  Time: 0:01:33 *\n",
            "Iter:    800,  Train Loss:  0.67,  Train Acc: 81.25%,  Val Loss:   0.5,  Val Acc: 84.04%,  Time: 0:01:48 *\n",
            "Iter:    900,  Train Loss:  0.64,  Train Acc: 81.25%,  Val Loss:  0.47,  Val Acc: 85.21%,  Time: 0:02:01 *\n",
            "Iter:   1000,  Train Loss:  0.48,  Train Acc: 82.81%,  Val Loss:  0.46,  Val Acc: 85.19%,  Time: 0:02:16 *\n",
            "Iter:   1100,  Train Loss:  0.46,  Train Acc: 85.94%,  Val Loss:  0.47,  Val Acc: 85.14%,  Time: 0:02:22 \n",
            "Iter:   1200,  Train Loss:  0.44,  Train Acc: 85.16%,  Val Loss:  0.44,  Val Acc: 86.02%,  Time: 0:02:31 *\n",
            "Iter:   1300,  Train Loss:  0.58,  Train Acc: 80.47%,  Val Loss:  0.43,  Val Acc: 86.49%,  Time: 0:02:46 *\n",
            "Iter:   1400,  Train Loss:  0.72,  Train Acc: 75.78%,  Val Loss:  0.43,  Val Acc: 86.50%,  Time: 0:03:01 *\n",
            "Epoch [2/20]\n",
            "Iter:   1500,  Train Loss:  0.55,  Train Acc: 81.25%,  Val Loss:  0.42,  Val Acc: 86.54%,  Time: 0:03:16 *\n",
            "Iter:   1600,  Train Loss:  0.41,  Train Acc: 85.16%,  Val Loss:  0.42,  Val Acc: 86.69%,  Time: 0:03:34 *\n",
            "Iter:   1700,  Train Loss:  0.52,  Train Acc: 84.38%,  Val Loss:  0.41,  Val Acc: 87.10%,  Time: 0:03:47 *\n",
            "Iter:   1800,  Train Loss:  0.37,  Train Acc: 89.84%,  Val Loss:  0.39,  Val Acc: 87.77%,  Time: 0:04:03 *\n",
            "Iter:   1900,  Train Loss:  0.45,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 87.61%,  Time: 0:04:19 *\n",
            "Iter:   2000,  Train Loss:  0.52,  Train Acc: 81.25%,  Val Loss:  0.37,  Val Acc: 88.06%,  Time: 0:04:33 *\n",
            "Iter:   2100,  Train Loss:  0.42,  Train Acc: 89.06%,  Val Loss:  0.37,  Val Acc: 88.30%,  Time: 0:04:50 *\n",
            "Iter:   2200,  Train Loss:  0.33,  Train Acc: 89.84%,  Val Loss:  0.37,  Val Acc: 88.61%,  Time: 0:05:05 *\n",
            "Iter:   2300,  Train Loss:  0.31,  Train Acc: 88.28%,  Val Loss:  0.36,  Val Acc: 88.83%,  Time: 0:05:18 *\n",
            "Iter:   2400,  Train Loss:  0.37,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 88.81%,  Time: 0:05:25 \n",
            "Iter:   2500,  Train Loss:  0.29,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 89.23%,  Time: 0:05:33 *\n",
            "Iter:   2600,  Train Loss:  0.37,  Train Acc: 85.16%,  Val Loss:  0.34,  Val Acc: 89.40%,  Time: 0:05:51 *\n",
            "Iter:   2700,  Train Loss:   0.3,  Train Acc: 88.28%,  Val Loss:  0.34,  Val Acc: 89.50%,  Time: 0:06:03 *\n",
            "Iter:   2800,  Train Loss:  0.49,  Train Acc: 83.59%,  Val Loss:  0.33,  Val Acc: 89.61%,  Time: 0:06:21 *\n",
            "Epoch [3/20]\n",
            "Iter:   2900,  Train Loss:  0.36,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.87%,  Time: 0:06:36 *\n",
            "Iter:   3000,  Train Loss:  0.35,  Train Acc: 86.72%,  Val Loss:  0.33,  Val Acc: 89.56%,  Time: 0:06:43 \n",
            "Iter:   3100,  Train Loss:  0.33,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 89.76%,  Time: 0:06:49 \n",
            "Iter:   3200,  Train Loss:  0.42,  Train Acc: 89.06%,  Val Loss:  0.32,  Val Acc: 89.94%,  Time: 0:06:58 *\n",
            "Iter:   3300,  Train Loss:   0.4,  Train Acc: 85.16%,  Val Loss:  0.32,  Val Acc: 89.80%,  Time: 0:07:05 \n",
            "Iter:   3400,  Train Loss:  0.44,  Train Acc: 84.38%,  Val Loss:  0.33,  Val Acc: 89.94%,  Time: 0:07:11 \n",
            "Iter:   3500,  Train Loss:  0.24,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 90.51%,  Time: 0:07:20 *\n",
            "Iter:   3600,  Train Loss:  0.23,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 90.48%,  Time: 0:07:27 \n",
            "Iter:   3700,  Train Loss:  0.33,  Train Acc: 86.72%,  Val Loss:  0.31,  Val Acc: 90.57%,  Time: 0:07:35 *\n",
            "Iter:   3800,  Train Loss:  0.32,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 90.52%,  Time: 0:07:42 \n",
            "Iter:   3900,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 90.42%,  Time: 0:07:48 \n",
            "Iter:   4000,  Train Loss:  0.19,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 90.45%,  Time: 0:07:57 *\n",
            "Iter:   4100,  Train Loss:  0.27,  Train Acc: 92.19%,  Val Loss:   0.3,  Val Acc: 90.62%,  Time: 0:08:06 *\n",
            "Iter:   4200,  Train Loss:  0.31,  Train Acc: 92.19%,  Val Loss:   0.3,  Val Acc: 90.55%,  Time: 0:08:15 *\n",
            "Epoch [4/20]\n",
            "Iter:   4300,  Train Loss:  0.21,  Train Acc: 92.97%,  Val Loss:   0.3,  Val Acc: 90.81%,  Time: 0:08:22 \n",
            "Iter:   4400,  Train Loss:  0.17,  Train Acc: 96.09%,  Val Loss:   0.3,  Val Acc: 90.92%,  Time: 0:08:30 *\n",
            "Iter:   4500,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.29,  Val Acc: 90.99%,  Time: 0:08:40 *\n",
            "Iter:   4600,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:   0.3,  Val Acc: 90.86%,  Time: 0:08:47 \n",
            "Iter:   4700,  Train Loss:  0.37,  Train Acc: 89.06%,  Val Loss:  0.29,  Val Acc: 91.21%,  Time: 0:08:56 *\n",
            "Iter:   4800,  Train Loss:  0.17,  Train Acc: 94.53%,  Val Loss:  0.29,  Val Acc: 91.24%,  Time: 0:09:02 \n",
            "Iter:   4900,  Train Loss:  0.27,  Train Acc: 90.62%,  Val Loss:  0.29,  Val Acc: 91.30%,  Time: 0:09:09 \n",
            "Iter:   5000,  Train Loss:  0.21,  Train Acc: 92.97%,  Val Loss:  0.29,  Val Acc: 91.02%,  Time: 0:09:15 \n",
            "Iter:   5100,  Train Loss:  0.27,  Train Acc: 89.84%,  Val Loss:  0.29,  Val Acc: 91.41%,  Time: 0:09:24 *\n",
            "Iter:   5200,  Train Loss:  0.29,  Train Acc: 90.62%,  Val Loss:  0.28,  Val Acc: 91.40%,  Time: 0:09:33 *\n",
            "Iter:   5300,  Train Loss:  0.24,  Train Acc: 92.97%,  Val Loss:  0.29,  Val Acc: 91.37%,  Time: 0:09:40 \n",
            "Iter:   5400,  Train Loss:  0.43,  Train Acc: 89.06%,  Val Loss:  0.29,  Val Acc: 91.15%,  Time: 0:09:46 \n",
            "Iter:   5500,  Train Loss:   0.2,  Train Acc: 92.19%,  Val Loss:  0.28,  Val Acc: 91.39%,  Time: 0:09:55 *\n",
            "Iter:   5600,  Train Loss:  0.13,  Train Acc: 94.53%,  Val Loss:  0.28,  Val Acc: 91.45%,  Time: 0:10:04 *\n",
            "Epoch [5/20]\n",
            "Iter:   5700,  Train Loss:  0.24,  Train Acc: 94.53%,  Val Loss:  0.28,  Val Acc: 91.65%,  Time: 0:10:15 *\n",
            "Iter:   5800,  Train Loss: 0.089,  Train Acc: 97.66%,  Val Loss:  0.29,  Val Acc: 91.24%,  Time: 0:10:21 \n",
            "Iter:   5900,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.28,  Val Acc: 91.54%,  Time: 0:10:28 \n",
            "Iter:   6000,  Train Loss:  0.19,  Train Acc: 92.97%,  Val Loss:  0.28,  Val Acc: 91.31%,  Time: 0:10:34 \n",
            "Iter:   6100,  Train Loss:  0.29,  Train Acc: 92.97%,  Val Loss:  0.29,  Val Acc: 91.21%,  Time: 0:10:41 \n",
            "Iter:   6200,  Train Loss:  0.13,  Train Acc: 96.88%,  Val Loss:  0.28,  Val Acc: 91.54%,  Time: 0:10:47 \n",
            "Iter:   6300,  Train Loss: 0.092,  Train Acc: 97.66%,  Val Loss:  0.28,  Val Acc: 91.62%,  Time: 0:10:54 \n",
            "Iter:   6400,  Train Loss: 0.047,  Train Acc: 99.22%,  Val Loss:  0.28,  Val Acc: 91.57%,  Time: 0:11:00 \n",
            "Iter:   6500,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.28,  Val Acc: 91.73%,  Time: 0:11:09 *\n",
            "Iter:   6600,  Train Loss:  0.12,  Train Acc: 94.53%,  Val Loss:  0.28,  Val Acc: 91.89%,  Time: 0:11:16 \n",
            "Iter:   6700,  Train Loss:  0.11,  Train Acc: 95.31%,  Val Loss:  0.28,  Val Acc: 91.57%,  Time: 0:11:22 \n",
            "Iter:   6800,  Train Loss:  0.17,  Train Acc: 92.19%,  Val Loss:  0.28,  Val Acc: 91.68%,  Time: 0:11:29 \n",
            "Iter:   6900,  Train Loss: 0.079,  Train Acc: 96.88%,  Val Loss:  0.28,  Val Acc: 91.60%,  Time: 0:11:36 \n",
            "Iter:   7000,  Train Loss:  0.18,  Train Acc: 94.53%,  Val Loss:  0.28,  Val Acc: 91.53%,  Time: 0:11:42 \n",
            "Epoch [6/20]\n",
            "Iter:   7100,  Train Loss: 0.086,  Train Acc: 96.88%,  Val Loss:  0.29,  Val Acc: 91.12%,  Time: 0:11:49 \n",
            "Iter:   7200,  Train Loss:  0.16,  Train Acc: 96.09%,  Val Loss:  0.29,  Val Acc: 91.72%,  Time: 0:11:55 \n",
            "Iter:   7300,  Train Loss:  0.12,  Train Acc: 96.88%,  Val Loss:  0.29,  Val Acc: 91.68%,  Time: 0:12:02 \n",
            "Iter:   7400,  Train Loss:  0.16,  Train Acc: 96.09%,  Val Loss:  0.29,  Val Acc: 91.24%,  Time: 0:12:08 \n",
            "Iter:   7500,  Train Loss:  0.11,  Train Acc: 95.31%,  Val Loss:  0.28,  Val Acc: 91.76%,  Time: 0:12:15 \n",
            "No optimization for a long time, auto-stopping...\n",
            "Test Loss:  0.26,  Test Acc: 91.92%\n",
            "Precision, Recall and F1-Score...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      finance     0.9402    0.8810    0.9097      1000\n",
            "       realty     0.9157    0.9450    0.9301      1000\n",
            "       stocks     0.8442    0.8830    0.8631      1000\n",
            "    education     0.9614    0.9470    0.9542      1000\n",
            "      science     0.8959    0.8690    0.8822      1000\n",
            "      society     0.8840    0.9220    0.9026      1000\n",
            "     politics     0.9070    0.8880    0.8974      1000\n",
            "       sports     0.9836    0.9620    0.9727      1000\n",
            "         game     0.9389    0.9530    0.9459      1000\n",
            "entertainment     0.9281    0.9420    0.9350      1000\n",
            "\n",
            "     accuracy                         0.9192     10000\n",
            "    macro avg     0.9199    0.9192    0.9193     10000\n",
            " weighted avg     0.9199    0.9192    0.9193     10000\n",
            "\n",
            "Confusion Matrix...\n",
            "[[881  13  69   2   7  12   8   2   3   3]\n",
            " [ 11 945  11   1   1  11   4   2   1  13]\n",
            " [ 33  28 883   0  23   2  22   0   6   3]\n",
            " [  1   4   2 947   5  19   9   1   3   9]\n",
            " [  3   7  32   4 869  19  18   0  34  14]\n",
            " [  2  15   3  13   8 922  20   1   5  11]\n",
            " [  4   9  34  11  13  34 888   1   1   5]\n",
            " [  0   5   3   2   4   6   5 962   0  13]\n",
            " [  0   1   7   2  28   5   1   1 953   2]\n",
            " [  2   5   2   3  12  13   4   8   9 942]]\n",
            "Time usage: 0:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TZQSOvnBrN6",
        "outputId": "1fefe210-f4ed-4187-ba8a-da48a31cec74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run.py --model TextCNN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Vocab size: 4762\n",
            "180000it [00:02, 79934.42it/s]\n",
            "10000it [00:00, 90621.23it/s]\n",
            "10000it [00:00, 47495.72it/s]\n",
            "Time usage: 0:00:03\n",
            "<bound method Module.parameters of Model(\n",
            "  (embedding): Embedding(4762, 300)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv2d(1, 256, kernel_size=(2, 300), stride=(1, 1))\n",
            "    (1): Conv2d(1, 256, kernel_size=(3, 300), stride=(1, 1))\n",
            "    (2): Conv2d(1, 256, kernel_size=(4, 300), stride=(1, 1))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=768, out_features=10, bias=True)\n",
            ")>\n",
            "Epoch [1/20]\n",
            "Iter:      0,  Train Loss:   2.3,  Train Acc: 10.94%,  Val Loss:   2.7,  Val Acc: 12.47%,  Time: 0:00:00 *\n",
            "Iter:    100,  Train Loss:  0.76,  Train Acc: 72.66%,  Val Loss:   0.7,  Val Acc: 78.61%,  Time: 0:00:04 *\n",
            "Iter:    200,  Train Loss:   0.7,  Train Acc: 78.91%,  Val Loss:  0.55,  Val Acc: 83.23%,  Time: 0:00:07 *\n",
            "Iter:    300,  Train Loss:  0.44,  Train Acc: 84.38%,  Val Loss:  0.49,  Val Acc: 85.07%,  Time: 0:00:10 *\n",
            "Iter:    400,  Train Loss:  0.77,  Train Acc: 79.69%,  Val Loss:  0.47,  Val Acc: 85.64%,  Time: 0:00:13 *\n",
            "Iter:    500,  Train Loss:  0.38,  Train Acc: 89.84%,  Val Loss:  0.44,  Val Acc: 86.41%,  Time: 0:00:16 *\n",
            "Iter:    600,  Train Loss:  0.52,  Train Acc: 84.38%,  Val Loss:  0.44,  Val Acc: 86.55%,  Time: 0:00:20 *\n",
            "Iter:    700,  Train Loss:  0.43,  Train Acc: 85.94%,  Val Loss:  0.41,  Val Acc: 87.33%,  Time: 0:00:23 *\n",
            "Iter:    800,  Train Loss:  0.46,  Train Acc: 86.72%,  Val Loss:  0.39,  Val Acc: 88.02%,  Time: 0:00:26 *\n",
            "Iter:    900,  Train Loss:  0.46,  Train Acc: 87.50%,  Val Loss:  0.39,  Val Acc: 88.15%,  Time: 0:00:30 *\n",
            "Iter:   1000,  Train Loss:   0.4,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 87.76%,  Time: 0:00:33 \n",
            "Iter:   1100,  Train Loss:  0.38,  Train Acc: 92.97%,  Val Loss:  0.39,  Val Acc: 88.19%,  Time: 0:00:36 *\n",
            "Iter:   1200,  Train Loss:  0.36,  Train Acc: 86.72%,  Val Loss:  0.37,  Val Acc: 88.69%,  Time: 0:00:40 *\n",
            "Iter:   1300,  Train Loss:  0.45,  Train Acc: 81.25%,  Val Loss:  0.37,  Val Acc: 88.76%,  Time: 0:00:43 *\n",
            "Iter:   1400,  Train Loss:  0.45,  Train Acc: 84.38%,  Val Loss:  0.36,  Val Acc: 88.73%,  Time: 0:00:46 *\n",
            "Epoch [2/20]\n",
            "Iter:   1500,  Train Loss:  0.38,  Train Acc: 88.28%,  Val Loss:  0.36,  Val Acc: 88.77%,  Time: 0:00:49 \n",
            "Iter:   1600,  Train Loss:  0.27,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 88.79%,  Time: 0:00:53 *\n",
            "Iter:   1700,  Train Loss:  0.42,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 89.44%,  Time: 0:00:56 *\n",
            "Iter:   1800,  Train Loss:   0.3,  Train Acc: 89.84%,  Val Loss:  0.36,  Val Acc: 88.94%,  Time: 0:00:59 \n",
            "Iter:   1900,  Train Loss:  0.35,  Train Acc: 89.84%,  Val Loss:  0.35,  Val Acc: 89.22%,  Time: 0:01:02 \n",
            "Iter:   2000,  Train Loss:  0.36,  Train Acc: 87.50%,  Val Loss:  0.34,  Val Acc: 89.53%,  Time: 0:01:06 *\n",
            "Iter:   2100,  Train Loss:  0.37,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 89.33%,  Time: 0:01:09 \n",
            "Iter:   2200,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.47%,  Time: 0:01:12 *\n",
            "Iter:   2300,  Train Loss:  0.41,  Train Acc: 92.97%,  Val Loss:  0.34,  Val Acc: 89.23%,  Time: 0:01:15 \n",
            "Iter:   2400,  Train Loss:  0.35,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.29%,  Time: 0:01:18 \n",
            "Iter:   2500,  Train Loss:  0.16,  Train Acc: 94.53%,  Val Loss:  0.34,  Val Acc: 89.54%,  Time: 0:01:22 *\n",
            "Iter:   2600,  Train Loss:  0.38,  Train Acc: 86.72%,  Val Loss:  0.34,  Val Acc: 89.95%,  Time: 0:01:25 *\n",
            "Iter:   2700,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 89.65%,  Time: 0:01:28 *\n",
            "Iter:   2800,  Train Loss:  0.38,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.67%,  Time: 0:01:31 \n",
            "Epoch [3/20]\n",
            "Iter:   2900,  Train Loss:  0.36,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 89.64%,  Time: 0:01:34 \n",
            "Iter:   3000,  Train Loss:   0.2,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.93%,  Time: 0:01:38 *\n",
            "Iter:   3100,  Train Loss:  0.28,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.51%,  Time: 0:01:41 \n",
            "Iter:   3200,  Train Loss:  0.36,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.64%,  Time: 0:01:44 \n",
            "Iter:   3300,  Train Loss:  0.36,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 89.78%,  Time: 0:01:47 *\n",
            "Iter:   3400,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.78%,  Time: 0:01:50 \n",
            "Iter:   3500,  Train Loss:   0.2,  Train Acc: 92.97%,  Val Loss:  0.34,  Val Acc: 89.75%,  Time: 0:01:54 \n",
            "Iter:   3600,  Train Loss:   0.2,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.82%,  Time: 0:01:57 *\n",
            "Iter:   3700,  Train Loss:   0.3,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 89.96%,  Time: 0:02:00 \n",
            "Iter:   3800,  Train Loss:  0.37,  Train Acc: 85.16%,  Val Loss:  0.33,  Val Acc: 89.89%,  Time: 0:02:03 \n",
            "Iter:   3900,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 90.29%,  Time: 0:02:07 *\n",
            "Iter:   4000,  Train Loss:  0.18,  Train Acc: 96.09%,  Val Loss:  0.33,  Val Acc: 89.76%,  Time: 0:02:10 \n",
            "Iter:   4100,  Train Loss:  0.28,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 90.05%,  Time: 0:02:13 \n",
            "Iter:   4200,  Train Loss:  0.29,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 89.97%,  Time: 0:02:16 \n",
            "Epoch [4/20]\n",
            "Iter:   4300,  Train Loss:   0.2,  Train Acc: 93.75%,  Val Loss:  0.33,  Val Acc: 89.76%,  Time: 0:02:20 \n",
            "Iter:   4400,  Train Loss:  0.22,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 90.02%,  Time: 0:02:23 \n",
            "Iter:   4500,  Train Loss:  0.33,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 90.12%,  Time: 0:02:26 \n",
            "Iter:   4600,  Train Loss:  0.24,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 90.35%,  Time: 0:02:29 \n",
            "Iter:   4700,  Train Loss:  0.33,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 90.50%,  Time: 0:02:33 *\n",
            "Iter:   4800,  Train Loss:  0.17,  Train Acc: 93.75%,  Val Loss:  0.32,  Val Acc: 90.46%,  Time: 0:02:36 \n",
            "Iter:   4900,  Train Loss:  0.25,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 90.08%,  Time: 0:02:39 \n",
            "Iter:   5000,  Train Loss:   0.3,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 90.08%,  Time: 0:02:42 \n",
            "Iter:   5100,  Train Loss:  0.25,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 90.12%,  Time: 0:02:45 \n",
            "Iter:   5200,  Train Loss:  0.33,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 90.38%,  Time: 0:02:49 \n",
            "Iter:   5300,  Train Loss:  0.18,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 90.31%,  Time: 0:02:52 *\n",
            "Iter:   5400,  Train Loss:  0.39,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 90.00%,  Time: 0:02:55 \n",
            "Iter:   5500,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 90.41%,  Time: 0:02:58 \n",
            "Iter:   5600,  Train Loss:  0.13,  Train Acc: 94.53%,  Val Loss:  0.32,  Val Acc: 90.33%,  Time: 0:03:01 \n",
            "Epoch [5/20]\n",
            "Iter:   5700,  Train Loss:  0.29,  Train Acc: 93.75%,  Val Loss:  0.32,  Val Acc: 90.12%,  Time: 0:03:05 \n",
            "Iter:   5800,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.33,  Val Acc: 90.55%,  Time: 0:03:08 \n",
            "Iter:   5900,  Train Loss:  0.16,  Train Acc: 93.75%,  Val Loss:  0.33,  Val Acc: 90.51%,  Time: 0:03:11 \n",
            "Iter:   6000,  Train Loss:  0.19,  Train Acc: 93.75%,  Val Loss:  0.32,  Val Acc: 90.52%,  Time: 0:03:14 \n",
            "Iter:   6100,  Train Loss:  0.24,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 90.28%,  Time: 0:03:17 \n",
            "Iter:   6200,  Train Loss:  0.13,  Train Acc: 97.66%,  Val Loss:  0.33,  Val Acc: 90.24%,  Time: 0:03:21 \n",
            "Iter:   6300,  Train Loss:  0.21,  Train Acc: 93.75%,  Val Loss:  0.33,  Val Acc: 90.20%,  Time: 0:03:24 \n",
            "No optimization for a long time, auto-stopping...\n",
            "Test Loss:   0.3,  Test Acc: 90.97%\n",
            "Precision, Recall and F1-Score...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      finance     0.9204    0.8670    0.8929      1000\n",
            "       realty     0.9202    0.9340    0.9270      1000\n",
            "       stocks     0.8225    0.8850    0.8526      1000\n",
            "    education     0.9419    0.9570    0.9494      1000\n",
            "      science     0.8464    0.8820    0.8639      1000\n",
            "      society     0.8968    0.9210    0.9087      1000\n",
            "     politics     0.9227    0.8710    0.8961      1000\n",
            "       sports     0.9642    0.9430    0.9535      1000\n",
            "         game     0.9457    0.9050    0.9249      1000\n",
            "entertainment     0.9292    0.9320    0.9306      1000\n",
            "\n",
            "     accuracy                         0.9097     10000\n",
            "    macro avg     0.9110    0.9097    0.9100     10000\n",
            " weighted avg     0.9110    0.9097    0.9100     10000\n",
            "\n",
            "Confusion Matrix...\n",
            "[[867  17  72   6  12   9   8   4   2   3]\n",
            " [ 11 934  20   3   5  13   3   1   3   7]\n",
            " [ 35  21 885   2  31   2  17   2   3   2]\n",
            " [  1   2   2 957   4  12   7   4   1  10]\n",
            " [  5   4  36   7 882  12  15   4  29   6]\n",
            " [  3  19   3  15  16 921  14   1   3   5]\n",
            " [ 10   8  33  14  23  34 871   2   0   5]\n",
            " [  3   3   8   1   5   8   4 943   3  22]\n",
            " [  5   1  11   5  47   6   2   7 905  11]\n",
            " [  2   6   6   6  17  10   3  10   8 932]]\n",
            "Time usage: 0:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg_WihCZBrGZ",
        "outputId": "e3d64676-06d3-421c-fae7-f925b0a3d80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run.py --model TextRCNN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Vocab size: 4762\n",
            "180000it [00:02, 82993.44it/s]\n",
            "10000it [00:00, 89986.25it/s]\n",
            "10000it [00:00, 47802.91it/s]\n",
            "Time usage: 0:00:02\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=1.0 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "<bound method Module.parameters of Model(\n",
            "  (embedding): Embedding(4762, 300)\n",
            "  (lstm): LSTM(300, 256, batch_first=True, dropout=1.0, bidirectional=True)\n",
            "  (maxpool): MaxPool1d(kernel_size=32, stride=32, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc): Linear(in_features=812, out_features=10, bias=True)\n",
            ")>\n",
            "Epoch [1/10]\n",
            "Iter:      0,  Train Loss:   2.6,  Train Acc:  5.47%,  Val Loss:   2.3,  Val Acc: 10.53%,  Time: 0:00:00 *\n",
            "Iter:    100,  Train Loss:  0.66,  Train Acc: 75.78%,  Val Loss:  0.72,  Val Acc: 76.47%,  Time: 0:00:02 *\n",
            "Iter:    200,  Train Loss:  0.67,  Train Acc: 78.12%,  Val Loss:  0.57,  Val Acc: 81.78%,  Time: 0:00:04 *\n",
            "Iter:    300,  Train Loss:  0.42,  Train Acc: 88.28%,  Val Loss:  0.49,  Val Acc: 84.31%,  Time: 0:00:05 *\n",
            "Iter:    400,  Train Loss:  0.55,  Train Acc: 81.25%,  Val Loss:  0.47,  Val Acc: 85.08%,  Time: 0:00:07 *\n",
            "Iter:    500,  Train Loss:   0.4,  Train Acc: 89.06%,  Val Loss:  0.42,  Val Acc: 86.53%,  Time: 0:00:08 *\n",
            "Iter:    600,  Train Loss:  0.49,  Train Acc: 83.59%,  Val Loss:  0.41,  Val Acc: 86.76%,  Time: 0:00:10 *\n",
            "Iter:    700,  Train Loss:  0.38,  Train Acc: 83.59%,  Val Loss:   0.4,  Val Acc: 87.02%,  Time: 0:00:12 *\n",
            "Iter:    800,  Train Loss:  0.32,  Train Acc: 91.41%,  Val Loss:  0.37,  Val Acc: 88.32%,  Time: 0:00:13 *\n",
            "Iter:    900,  Train Loss:  0.37,  Train Acc: 88.28%,  Val Loss:  0.35,  Val Acc: 88.43%,  Time: 0:00:15 *\n",
            "Iter:   1000,  Train Loss:  0.22,  Train Acc: 92.19%,  Val Loss:  0.35,  Val Acc: 88.64%,  Time: 0:00:16 *\n",
            "Iter:   1100,  Train Loss:  0.24,  Train Acc: 92.19%,  Val Loss:  0.37,  Val Acc: 87.72%,  Time: 0:00:18 \n",
            "Iter:   1200,  Train Loss:   0.3,  Train Acc: 89.84%,  Val Loss:  0.35,  Val Acc: 88.85%,  Time: 0:00:20 \n",
            "Iter:   1300,  Train Loss:  0.32,  Train Acc: 86.72%,  Val Loss:  0.34,  Val Acc: 89.30%,  Time: 0:00:21 *\n",
            "Iter:   1400,  Train Loss:  0.39,  Train Acc: 89.06%,  Val Loss:  0.34,  Val Acc: 89.04%,  Time: 0:00:23 \n",
            "Epoch [2/10]\n",
            "Iter:   1500,  Train Loss:  0.32,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.47%,  Time: 0:00:24 *\n",
            "Iter:   1600,  Train Loss:  0.28,  Train Acc: 89.84%,  Val Loss:  0.35,  Val Acc: 89.08%,  Time: 0:00:26 \n",
            "Iter:   1700,  Train Loss:   0.3,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.41%,  Time: 0:00:28 \n",
            "Iter:   1800,  Train Loss:   0.2,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 89.54%,  Time: 0:00:29 *\n",
            "Iter:   1900,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.31,  Val Acc: 89.86%,  Time: 0:00:31 *\n",
            "Iter:   2000,  Train Loss:  0.34,  Train Acc: 89.06%,  Val Loss:  0.31,  Val Acc: 90.21%,  Time: 0:00:32 *\n",
            "Iter:   2100,  Train Loss:  0.31,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 89.90%,  Time: 0:00:34 \n",
            "Iter:   2200,  Train Loss:  0.16,  Train Acc: 95.31%,  Val Loss:   0.3,  Val Acc: 90.05%,  Time: 0:00:36 *\n",
            "Iter:   2300,  Train Loss:  0.23,  Train Acc: 93.75%,  Val Loss:  0.29,  Val Acc: 90.65%,  Time: 0:00:37 *\n",
            "Iter:   2400,  Train Loss:   0.2,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.64%,  Time: 0:00:39 \n",
            "Iter:   2500,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.31,  Val Acc: 89.99%,  Time: 0:00:40 \n",
            "Iter:   2600,  Train Loss:  0.26,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 90.37%,  Time: 0:00:42 \n",
            "Iter:   2700,  Train Loss:  0.21,  Train Acc: 93.75%,  Val Loss:  0.29,  Val Acc: 90.62%,  Time: 0:00:43 \n",
            "Iter:   2800,  Train Loss:  0.32,  Train Acc: 89.84%,  Val Loss:   0.3,  Val Acc: 90.30%,  Time: 0:00:45 \n",
            "Epoch [3/10]\n",
            "Iter:   2900,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:   0.3,  Val Acc: 90.41%,  Time: 0:00:47 \n",
            "Iter:   3000,  Train Loss:  0.19,  Train Acc: 93.75%,  Val Loss:   0.3,  Val Acc: 90.52%,  Time: 0:00:48 \n",
            "Iter:   3100,  Train Loss:  0.16,  Train Acc: 95.31%,  Val Loss:  0.33,  Val Acc: 89.70%,  Time: 0:00:50 \n",
            "Iter:   3200,  Train Loss:  0.31,  Train Acc: 93.75%,  Val Loss:   0.3,  Val Acc: 90.25%,  Time: 0:00:51 \n",
            "Iter:   3300,  Train Loss:  0.29,  Train Acc: 90.62%,  Val Loss:   0.3,  Val Acc: 90.45%,  Time: 0:00:53 \n",
            "No optimization for a long time, auto-stopping...\n",
            "Test Loss:  0.28,  Test Acc: 90.88%\n",
            "Precision, Recall and F1-Score...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      finance     0.9019    0.9010    0.9015      1000\n",
            "       realty     0.9102    0.9320    0.9209      1000\n",
            "       stocks     0.8577    0.8320    0.8447      1000\n",
            "    education     0.9487    0.9430    0.9458      1000\n",
            "      science     0.8743    0.8350    0.8542      1000\n",
            "      society     0.8674    0.9290    0.8972      1000\n",
            "     politics     0.8858    0.8690    0.8773      1000\n",
            "       sports     0.9829    0.9750    0.9789      1000\n",
            "         game     0.9445    0.9190    0.9316      1000\n",
            "entertainment     0.9155    0.9530    0.9339      1000\n",
            "\n",
            "     accuracy                         0.9088     10000\n",
            "    macro avg     0.9089    0.9088    0.9086     10000\n",
            " weighted avg     0.9089    0.9088    0.9086     10000\n",
            "\n",
            "Confusion Matrix...\n",
            "[[901  17  43   5   8  13   6   1   3   3]\n",
            " [ 13 932  17   0   5  19   4   1   0   9]\n",
            " [ 58  29 832   2  30   4  38   0   5   2]\n",
            " [  2   3   2 943   9  18   5   1   3  14]\n",
            " [  9   7  33   9 835  22  23   4  34  24]\n",
            " [  0  11   2  18   5 929  21   0   1  13]\n",
            " [ 10  10  28  11  16  43 869   4   2   7]\n",
            " [  0   3   1   0   1   8   3 975   0   9]\n",
            " [  2   6   9   2  40  10   4   1 919   7]\n",
            " [  4   6   3   4   6   5   8   5   6 953]]\n",
            "Time usage: 0:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFmaOOes6xG3",
        "outputId": "75cfaca0-386e-4313-9488-9428b7496342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run.py --model TextRNN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Vocab size: 4762\n",
            "180000it [00:02, 81338.97it/s]\n",
            "10000it [00:00, 95163.10it/s]\n",
            "10000it [00:00, 50019.25it/s]\n",
            "Time usage: 0:00:03\n",
            "<bound method Module.parameters of Model(\n",
            "  (embedding): Embedding(4762, 300)\n",
            "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
            ")>\n",
            "Epoch [1/10]\n",
            "Iter:      0,  Train Loss:   2.3,  Train Acc:  7.81%,  Val Loss:   2.3,  Val Acc: 10.00%,  Time: 0:00:00 *\n",
            "Iter:    100,  Train Loss:   1.7,  Train Acc: 39.06%,  Val Loss:   1.6,  Val Acc: 39.53%,  Time: 0:00:02 *\n",
            "Iter:    200,  Train Loss:   1.4,  Train Acc: 45.31%,  Val Loss:   1.3,  Val Acc: 52.07%,  Time: 0:00:04 *\n",
            "Iter:    300,  Train Loss:  0.93,  Train Acc: 67.97%,  Val Loss:   1.0,  Val Acc: 65.41%,  Time: 0:00:05 *\n",
            "Iter:    400,  Train Loss:  0.72,  Train Acc: 75.00%,  Val Loss:  0.72,  Val Acc: 76.77%,  Time: 0:00:07 *\n",
            "Iter:    500,  Train Loss:  0.59,  Train Acc: 80.47%,  Val Loss:  0.63,  Val Acc: 79.83%,  Time: 0:00:09 *\n",
            "Iter:    600,  Train Loss:  0.61,  Train Acc: 80.47%,  Val Loss:  0.56,  Val Acc: 82.09%,  Time: 0:00:10 *\n",
            "Iter:    700,  Train Loss:  0.51,  Train Acc: 84.38%,  Val Loss:   0.5,  Val Acc: 84.38%,  Time: 0:00:12 *\n",
            "Iter:    800,  Train Loss:  0.48,  Train Acc: 86.72%,  Val Loss:  0.48,  Val Acc: 84.87%,  Time: 0:00:13 *\n",
            "Iter:    900,  Train Loss:  0.49,  Train Acc: 84.38%,  Val Loss:  0.46,  Val Acc: 85.43%,  Time: 0:00:15 *\n",
            "Iter:   1000,  Train Loss:   0.3,  Train Acc: 89.06%,  Val Loss:  0.45,  Val Acc: 85.47%,  Time: 0:00:17 *\n",
            "Iter:   1100,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.43,  Val Acc: 85.99%,  Time: 0:00:18 *\n",
            "Iter:   1200,  Train Loss:  0.36,  Train Acc: 88.28%,  Val Loss:  0.42,  Val Acc: 86.95%,  Time: 0:00:20 *\n",
            "Iter:   1300,  Train Loss:  0.38,  Train Acc: 85.94%,  Val Loss:  0.41,  Val Acc: 87.41%,  Time: 0:00:22 *\n",
            "Iter:   1400,  Train Loss:  0.48,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 87.57%,  Time: 0:00:23 *\n",
            "Epoch [2/10]\n",
            "Iter:   1500,  Train Loss:  0.39,  Train Acc: 86.72%,  Val Loss:  0.38,  Val Acc: 87.84%,  Time: 0:00:25 *\n",
            "Iter:   1600,  Train Loss:  0.39,  Train Acc: 89.84%,  Val Loss:   0.4,  Val Acc: 87.46%,  Time: 0:00:27 \n",
            "Iter:   1700,  Train Loss:  0.39,  Train Acc: 85.94%,  Val Loss:  0.41,  Val Acc: 87.10%,  Time: 0:00:28 \n",
            "Iter:   1800,  Train Loss:  0.29,  Train Acc: 89.06%,  Val Loss:  0.38,  Val Acc: 88.03%,  Time: 0:00:30 \n",
            "Iter:   1900,  Train Loss:  0.34,  Train Acc: 87.50%,  Val Loss:  0.34,  Val Acc: 88.83%,  Time: 0:00:32 *\n",
            "Iter:   2000,  Train Loss:  0.36,  Train Acc: 87.50%,  Val Loss:  0.35,  Val Acc: 88.75%,  Time: 0:00:33 \n",
            "Iter:   2100,  Train Loss:  0.43,  Train Acc: 87.50%,  Val Loss:  0.35,  Val Acc: 88.89%,  Time: 0:00:35 \n",
            "Iter:   2200,  Train Loss:  0.25,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 88.99%,  Time: 0:00:37 \n",
            "Iter:   2300,  Train Loss:  0.27,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.34%,  Time: 0:00:38 *\n",
            "Iter:   2400,  Train Loss:  0.22,  Train Acc: 94.53%,  Val Loss:  0.36,  Val Acc: 88.80%,  Time: 0:00:40 \n",
            "Iter:   2500,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.39%,  Time: 0:00:42 \n",
            "Iter:   2600,  Train Loss:  0.33,  Train Acc: 92.19%,  Val Loss:  0.34,  Val Acc: 89.35%,  Time: 0:00:43 \n",
            "Iter:   2700,  Train Loss:  0.29,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.39%,  Time: 0:00:45 *\n",
            "Iter:   2800,  Train Loss:   0.4,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 89.66%,  Time: 0:00:47 *\n",
            "Epoch [3/10]\n",
            "Iter:   2900,  Train Loss:  0.38,  Train Acc: 89.06%,  Val Loss:  0.34,  Val Acc: 89.46%,  Time: 0:00:48 \n",
            "Iter:   3000,  Train Loss:  0.29,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.35%,  Time: 0:00:50 \n",
            "Iter:   3100,  Train Loss:  0.21,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.28%,  Time: 0:00:52 \n",
            "Iter:   3200,  Train Loss:  0.38,  Train Acc: 90.62%,  Val Loss:  0.36,  Val Acc: 88.50%,  Time: 0:00:53 \n",
            "Iter:   3300,  Train Loss:  0.27,  Train Acc: 89.06%,  Val Loss:  0.31,  Val Acc: 89.87%,  Time: 0:00:55 *\n",
            "Iter:   3400,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 89.52%,  Time: 0:00:57 \n",
            "Iter:   3500,  Train Loss:  0.23,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 89.67%,  Time: 0:00:58 \n",
            "Iter:   3600,  Train Loss:  0.18,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.61%,  Time: 0:01:00 \n",
            "Iter:   3700,  Train Loss:  0.33,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 89.81%,  Time: 0:01:02 \n",
            "Iter:   3800,  Train Loss:  0.28,  Train Acc: 89.06%,  Val Loss:  0.31,  Val Acc: 90.21%,  Time: 0:01:03 *\n",
            "Iter:   3900,  Train Loss:  0.28,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 90.16%,  Time: 0:01:05 \n",
            "Iter:   4000,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 89.74%,  Time: 0:01:07 \n",
            "Iter:   4100,  Train Loss:  0.28,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 90.18%,  Time: 0:01:09 *\n",
            "Iter:   4200,  Train Loss:  0.27,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 90.14%,  Time: 0:01:10 \n",
            "Epoch [4/10]\n",
            "Iter:   4300,  Train Loss:  0.25,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 89.88%,  Time: 0:01:12 \n",
            "Iter:   4400,  Train Loss:  0.21,  Train Acc: 93.75%,  Val Loss:  0.31,  Val Acc: 90.41%,  Time: 0:01:14 \n",
            "Iter:   4500,  Train Loss:  0.27,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 89.89%,  Time: 0:01:15 \n",
            "Iter:   4600,  Train Loss:  0.24,  Train Acc: 90.62%,  Val Loss:   0.3,  Val Acc: 90.32%,  Time: 0:01:17 *\n",
            "Iter:   4700,  Train Loss:  0.32,  Train Acc: 90.62%,  Val Loss:   0.3,  Val Acc: 90.44%,  Time: 0:01:19 *\n",
            "Iter:   4800,  Train Loss:  0.11,  Train Acc: 96.09%,  Val Loss:  0.31,  Val Acc: 90.31%,  Time: 0:01:21 \n",
            "Iter:   4900,  Train Loss:  0.18,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 90.41%,  Time: 0:01:22 \n",
            "Iter:   5000,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.34,  Val Acc: 89.50%,  Time: 0:01:24 \n",
            "Iter:   5100,  Train Loss:  0.19,  Train Acc: 89.06%,  Val Loss:  0.32,  Val Acc: 90.10%,  Time: 0:01:26 \n",
            "Iter:   5200,  Train Loss:   0.3,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 90.19%,  Time: 0:01:27 \n",
            "Iter:   5300,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.32,  Val Acc: 90.10%,  Time: 0:01:29 \n",
            "Iter:   5400,  Train Loss:  0.31,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 90.22%,  Time: 0:01:31 \n",
            "Iter:   5500,  Train Loss:  0.23,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 90.56%,  Time: 0:01:33 \n",
            "Iter:   5600,  Train Loss:  0.13,  Train Acc: 93.75%,  Val Loss:   0.3,  Val Acc: 90.02%,  Time: 0:01:34 \n",
            "Epoch [5/10]\n",
            "Iter:   5700,  Train Loss:  0.26,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 90.34%,  Time: 0:01:36 \n",
            "No optimization for a long time, auto-stopping...\n",
            "Test Loss:  0.29,  Test Acc: 90.88%\n",
            "Precision, Recall and F1-Score...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      finance     0.9142    0.8950    0.9045      1000\n",
            "       realty     0.9091    0.9300    0.9194      1000\n",
            "       stocks     0.8911    0.8100    0.8486      1000\n",
            "    education     0.9283    0.9580    0.9429      1000\n",
            "      science     0.8375    0.8710    0.8539      1000\n",
            "      society     0.8713    0.9340    0.9015      1000\n",
            "     politics     0.9128    0.8480    0.8792      1000\n",
            "       sports     0.9760    0.9760    0.9760      1000\n",
            "         game     0.9327    0.9290    0.9309      1000\n",
            "entertainment     0.9186    0.9370    0.9277      1000\n",
            "\n",
            "     accuracy                         0.9088     10000\n",
            "    macro avg     0.9092    0.9088    0.9085     10000\n",
            " weighted avg     0.9092    0.9088    0.9085     10000\n",
            "\n",
            "Confusion Matrix...\n",
            "[[895  22  31   8  11  11  11   3   2   6]\n",
            " [  7 930  14   3   7  17   4   2   7   9]\n",
            " [ 58  31 810   5  46   6  28   2  11   3]\n",
            " [  0   0   0 958   3  20   6   0   1  12]\n",
            " [  5   5  22   9 871  25  15   1  33  14]\n",
            " [  0  16   2  16   9 934  10   0   3  10]\n",
            " [ 10   7  23  18  34  42 848   3   4  11]\n",
            " [  0   3   2   1   0   4   3 976   1  10]\n",
            " [  1   2   5   4  43   5   1   2 929   8]\n",
            " [  3   7   0  10  16   8   3  11   5 937]]\n",
            "Time usage: 0:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWPDCllOBq4N",
        "outputId": "d5941b5e-1ded-43b5-fc63-39b10f361471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run.py --model TextRNN_Att"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Vocab size: 4762\n",
            "180000it [00:02, 78530.76it/s]\n",
            "10000it [00:00, 93679.52it/s]\n",
            "10000it [00:00, 45551.59it/s]\n",
            "Time usage: 0:00:03\n",
            "<bound method Module.parameters of Model(\n",
            "  (embedding): Embedding(4762, 300)\n",
            "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (tanh1): Tanh()\n",
            "  (tanh2): Tanh()\n",
            "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
            ")>\n",
            "Epoch [1/10]\n",
            "Iter:      0,  Train Loss:   2.3,  Train Acc:  9.38%,  Val Loss:   2.3,  Val Acc: 10.28%,  Time: 0:00:00 *\n",
            "Iter:    100,  Train Loss:  0.72,  Train Acc: 75.78%,  Val Loss:  0.76,  Val Acc: 73.59%,  Time: 0:00:02 *\n",
            "Iter:    200,  Train Loss:  0.76,  Train Acc: 75.00%,  Val Loss:  0.58,  Val Acc: 81.41%,  Time: 0:00:04 *\n",
            "Iter:    300,  Train Loss:  0.39,  Train Acc: 90.62%,  Val Loss:  0.52,  Val Acc: 83.42%,  Time: 0:00:06 *\n",
            "Iter:    400,  Train Loss:  0.54,  Train Acc: 83.59%,  Val Loss:  0.48,  Val Acc: 84.55%,  Time: 0:00:08 *\n",
            "Iter:    500,  Train Loss:  0.39,  Train Acc: 89.06%,  Val Loss:  0.44,  Val Acc: 85.80%,  Time: 0:00:09 *\n",
            "Iter:    600,  Train Loss:  0.48,  Train Acc: 85.94%,  Val Loss:  0.42,  Val Acc: 86.63%,  Time: 0:00:11 *\n",
            "Iter:    700,  Train Loss:   0.4,  Train Acc: 84.38%,  Val Loss:  0.41,  Val Acc: 86.53%,  Time: 0:00:13 *\n",
            "Iter:    800,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.39,  Val Acc: 87.65%,  Time: 0:00:15 *\n",
            "Iter:    900,  Train Loss:  0.42,  Train Acc: 88.28%,  Val Loss:  0.37,  Val Acc: 87.92%,  Time: 0:00:17 *\n",
            "Iter:   1000,  Train Loss:  0.22,  Train Acc: 92.19%,  Val Loss:  0.38,  Val Acc: 87.74%,  Time: 0:00:18 \n",
            "Iter:   1100,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.37,  Val Acc: 88.03%,  Time: 0:00:20 \n",
            "Iter:   1200,  Train Loss:  0.31,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 88.67%,  Time: 0:00:22 *\n",
            "Iter:   1300,  Train Loss:  0.35,  Train Acc: 87.50%,  Val Loss:  0.36,  Val Acc: 88.67%,  Time: 0:00:24 \n",
            "Iter:   1400,  Train Loss:  0.42,  Train Acc: 85.94%,  Val Loss:  0.35,  Val Acc: 89.01%,  Time: 0:00:26 *\n",
            "Epoch [2/10]\n",
            "Iter:   1500,  Train Loss:  0.42,  Train Acc: 87.50%,  Val Loss:  0.36,  Val Acc: 88.31%,  Time: 0:00:27 \n",
            "Iter:   1600,  Train Loss:  0.33,  Train Acc: 85.94%,  Val Loss:  0.38,  Val Acc: 88.37%,  Time: 0:00:29 \n",
            "Iter:   1700,  Train Loss:  0.33,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 88.70%,  Time: 0:00:31 \n",
            "Iter:   1800,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.01%,  Time: 0:00:33 *\n",
            "Iter:   1900,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 89.50%,  Time: 0:00:35 *\n",
            "Iter:   2000,  Train Loss:  0.28,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 89.18%,  Time: 0:00:37 \n",
            "Iter:   2100,  Train Loss:  0.35,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 89.54%,  Time: 0:00:38 \n",
            "Iter:   2200,  Train Loss:   0.2,  Train Acc: 93.75%,  Val Loss:  0.33,  Val Acc: 89.35%,  Time: 0:00:40 \n",
            "Iter:   2300,  Train Loss:  0.28,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 90.08%,  Time: 0:00:42 *\n",
            "Iter:   2400,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:  0.34,  Val Acc: 89.13%,  Time: 0:00:44 \n",
            "Iter:   2500,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.31,  Val Acc: 89.83%,  Time: 0:00:46 \n",
            "Iter:   2600,  Train Loss:  0.26,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 89.61%,  Time: 0:00:47 \n",
            "Iter:   2700,  Train Loss:  0.27,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 90.16%,  Time: 0:00:49 *\n",
            "Iter:   2800,  Train Loss:  0.36,  Train Acc: 87.50%,  Val Loss:  0.31,  Val Acc: 90.03%,  Time: 0:00:51 \n",
            "Epoch [3/10]\n",
            "Iter:   2900,  Train Loss:  0.33,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 89.85%,  Time: 0:00:53 \n",
            "Iter:   3000,  Train Loss:  0.18,  Train Acc: 94.53%,  Val Loss:  0.32,  Val Acc: 89.82%,  Time: 0:00:54 \n",
            "Iter:   3100,  Train Loss:  0.17,  Train Acc: 95.31%,  Val Loss:  0.32,  Val Acc: 89.71%,  Time: 0:00:56 \n",
            "Iter:   3200,  Train Loss:  0.38,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 89.58%,  Time: 0:00:58 \n",
            "Iter:   3300,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 89.97%,  Time: 0:01:00 \n",
            "Iter:   3400,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 90.30%,  Time: 0:01:02 \n",
            "Iter:   3500,  Train Loss:  0.15,  Train Acc: 96.09%,  Val Loss:  0.32,  Val Acc: 89.66%,  Time: 0:01:03 \n",
            "Iter:   3600,  Train Loss:  0.18,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 90.36%,  Time: 0:01:05 \n",
            "Iter:   3700,  Train Loss:  0.28,  Train Acc: 89.84%,  Val Loss:   0.3,  Val Acc: 90.41%,  Time: 0:01:07 *\n",
            "Iter:   3800,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 90.00%,  Time: 0:01:09 \n",
            "Iter:   3900,  Train Loss:  0.25,  Train Acc: 92.97%,  Val Loss:   0.3,  Val Acc: 90.25%,  Time: 0:01:10 \n",
            "Iter:   4000,  Train Loss:   0.2,  Train Acc: 94.53%,  Val Loss:  0.32,  Val Acc: 89.97%,  Time: 0:01:12 \n",
            "Iter:   4100,  Train Loss:  0.22,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 89.91%,  Time: 0:01:14 \n",
            "Iter:   4200,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 90.14%,  Time: 0:01:16 \n",
            "Epoch [4/10]\n",
            "Iter:   4300,  Train Loss:  0.18,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 90.03%,  Time: 0:01:18 \n",
            "Iter:   4400,  Train Loss:  0.13,  Train Acc: 95.31%,  Val Loss:  0.31,  Val Acc: 90.40%,  Time: 0:01:19 \n",
            "Iter:   4500,  Train Loss:  0.27,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 90.21%,  Time: 0:01:21 \n",
            "Iter:   4600,  Train Loss:  0.18,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 90.38%,  Time: 0:01:23 \n",
            "Iter:   4700,  Train Loss:  0.31,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 90.58%,  Time: 0:01:25 \n",
            "No optimization for a long time, auto-stopping...\n",
            "Test Loss:  0.29,  Test Acc: 90.65%\n",
            "Precision, Recall and F1-Score...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      finance     0.9391    0.8640    0.9000      1000\n",
            "       realty     0.9037    0.9290    0.9162      1000\n",
            "       stocks     0.8448    0.8440    0.8444      1000\n",
            "    education     0.9540    0.9340    0.9439      1000\n",
            "      science     0.8278    0.8750    0.8508      1000\n",
            "      society     0.8715    0.9360    0.9026      1000\n",
            "     politics     0.8807    0.8710    0.8758      1000\n",
            "       sports     0.9877    0.9660    0.9767      1000\n",
            "         game     0.9592    0.8930    0.9249      1000\n",
            "entertainment     0.9120    0.9530    0.9320      1000\n",
            "\n",
            "     accuracy                         0.9065     10000\n",
            "    macro avg     0.9081    0.9065    0.9067     10000\n",
            " weighted avg     0.9081    0.9065    0.9067     10000\n",
            "\n",
            "Confusion Matrix...\n",
            "[[864  18  69   4  15  15   9   1   1   4]\n",
            " [  8 929  20   0   6  19   7   2   1   8]\n",
            " [ 34  31 844   3  40   4  38   0   4   2]\n",
            " [  0   4   3 934  11  18  13   1   5  11]\n",
            " [  4   9  32   8 875  16  16   1  19  20]\n",
            " [  0  14   0  15   8 936  16   0   2   9]\n",
            " [  6   8  19  10  28  45 871   1   2  10]\n",
            " [  0   3   1   1   2   7   6 966   0  14]\n",
            " [  1   6   9   1  59   8   7   2 893  14]\n",
            " [  3   6   2   3  13   6   6   4   4 953]]\n",
            "Time usage: 0:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9u9jFCuBe5Z",
        "outputId": "db8b90bc-207b-4ab1-d2f5-ade8984033bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run.py --model Transformer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Vocab size: 4762\n",
            "180000it [00:02, 80098.34it/s]\n",
            "10000it [00:00, 86825.83it/s]\n",
            "10000it [00:00, 45934.67it/s]\n",
            "Time usage: 0:00:03\n",
            "<bound method Module.parameters of Model(\n",
            "  (embedding): Embedding(4762, 300)\n",
            "  (postion_embedding): Positional_Encoding(\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (encoder): Encoder(\n",
            "    (attention): Multi_Head_Attention(\n",
            "      (fc_Q): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (fc_K): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (fc_V): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (attention): Scaled_Dot_Product_Attention()\n",
            "      (fc): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (feed_forward): Position_wise_Feed_Forward(\n",
            "      (fc1): Linear(in_features=300, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=300, bias=True)\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (encoders): ModuleList(\n",
            "    (0): Encoder(\n",
            "      (attention): Multi_Head_Attention(\n",
            "        (fc_Q): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (fc_K): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (fc_V): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (attention): Scaled_Dot_Product_Attention()\n",
            "        (fc): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (dropout): Dropout(p=0.5, inplace=False)\n",
            "        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (feed_forward): Position_wise_Feed_Forward(\n",
            "        (fc1): Linear(in_features=300, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=300, bias=True)\n",
            "        (dropout): Dropout(p=0.5, inplace=False)\n",
            "        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Encoder(\n",
            "      (attention): Multi_Head_Attention(\n",
            "        (fc_Q): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (fc_K): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (fc_V): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (attention): Scaled_Dot_Product_Attention()\n",
            "        (fc): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (dropout): Dropout(p=0.5, inplace=False)\n",
            "        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (feed_forward): Position_wise_Feed_Forward(\n",
            "        (fc1): Linear(in_features=300, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=300, bias=True)\n",
            "        (dropout): Dropout(p=0.5, inplace=False)\n",
            "        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fc1): Linear(in_features=9600, out_features=10, bias=True)\n",
            ")>\n",
            "Epoch [1/20]\n",
            "Iter:      0,  Train Loss:   2.4,  Train Acc: 14.06%,  Val Loss:   4.8,  Val Acc: 10.00%,  Time: 0:00:01 *\n",
            "Iter:    100,  Train Loss:   1.5,  Train Acc: 50.00%,  Val Loss:   1.9,  Val Acc: 50.01%,  Time: 0:00:04 *\n",
            "Iter:    200,  Train Loss:   1.2,  Train Acc: 58.59%,  Val Loss:   1.1,  Val Acc: 68.38%,  Time: 0:00:07 *\n",
            "Iter:    300,  Train Loss:  0.75,  Train Acc: 69.53%,  Val Loss:  0.83,  Val Acc: 74.39%,  Time: 0:00:10 *\n",
            "Iter:    400,  Train Loss:  0.95,  Train Acc: 70.31%,  Val Loss:  0.82,  Val Acc: 76.41%,  Time: 0:00:13 *\n",
            "Iter:    500,  Train Loss:  0.88,  Train Acc: 70.31%,  Val Loss:  0.86,  Val Acc: 75.93%,  Time: 0:00:16 \n",
            "Iter:    600,  Train Loss:  0.85,  Train Acc: 75.78%,  Val Loss:  0.75,  Val Acc: 79.29%,  Time: 0:00:19 *\n",
            "Iter:    700,  Train Loss:  0.67,  Train Acc: 75.78%,  Val Loss:  0.79,  Val Acc: 79.42%,  Time: 0:00:23 \n",
            "Iter:    800,  Train Loss:  0.59,  Train Acc: 83.59%,  Val Loss:  0.66,  Val Acc: 81.54%,  Time: 0:00:26 *\n",
            "Iter:    900,  Train Loss:  0.63,  Train Acc: 79.69%,  Val Loss:  0.62,  Val Acc: 82.39%,  Time: 0:00:29 *\n",
            "Iter:   1000,  Train Loss:  0.55,  Train Acc: 80.47%,  Val Loss:  0.64,  Val Acc: 82.08%,  Time: 0:00:32 \n",
            "Iter:   1100,  Train Loss:  0.51,  Train Acc: 77.34%,  Val Loss:  0.63,  Val Acc: 82.40%,  Time: 0:00:35 \n",
            "Iter:   1200,  Train Loss:  0.55,  Train Acc: 81.25%,  Val Loss:   0.6,  Val Acc: 83.28%,  Time: 0:00:39 *\n",
            "Iter:   1300,  Train Loss:  0.65,  Train Acc: 78.91%,  Val Loss:  0.55,  Val Acc: 84.57%,  Time: 0:00:42 *\n",
            "Iter:   1400,  Train Loss:  0.73,  Train Acc: 78.12%,  Val Loss:  0.61,  Val Acc: 83.33%,  Time: 0:00:45 \n",
            "Epoch [2/20]\n",
            "Iter:   1500,  Train Loss:  0.59,  Train Acc: 80.47%,  Val Loss:  0.53,  Val Acc: 85.14%,  Time: 0:00:48 *\n",
            "Iter:   1600,  Train Loss:  0.51,  Train Acc: 79.69%,  Val Loss:  0.61,  Val Acc: 83.83%,  Time: 0:00:51 \n",
            "Iter:   1700,  Train Loss:  0.49,  Train Acc: 84.38%,  Val Loss:  0.59,  Val Acc: 84.30%,  Time: 0:00:54 \n",
            "Iter:   1800,  Train Loss:  0.38,  Train Acc: 88.28%,  Val Loss:  0.54,  Val Acc: 86.05%,  Time: 0:00:57 \n",
            "Iter:   1900,  Train Loss:  0.48,  Train Acc: 82.03%,  Val Loss:  0.52,  Val Acc: 85.64%,  Time: 0:01:00 *\n",
            "Iter:   2000,  Train Loss:  0.57,  Train Acc: 78.91%,  Val Loss:  0.55,  Val Acc: 85.14%,  Time: 0:01:03 \n",
            "Iter:   2100,  Train Loss:   0.6,  Train Acc: 79.69%,  Val Loss:  0.56,  Val Acc: 84.96%,  Time: 0:01:07 \n",
            "Iter:   2200,  Train Loss:  0.41,  Train Acc: 85.16%,  Val Loss:  0.54,  Val Acc: 85.73%,  Time: 0:01:10 \n",
            "Iter:   2300,  Train Loss:  0.45,  Train Acc: 84.38%,  Val Loss:  0.51,  Val Acc: 85.55%,  Time: 0:01:13 *\n",
            "Iter:   2400,  Train Loss:  0.58,  Train Acc: 82.03%,  Val Loss:  0.55,  Val Acc: 85.77%,  Time: 0:01:16 \n",
            "Iter:   2500,  Train Loss:  0.53,  Train Acc: 78.91%,  Val Loss:  0.55,  Val Acc: 84.86%,  Time: 0:01:19 \n",
            "Iter:   2600,  Train Loss:  0.47,  Train Acc: 84.38%,  Val Loss:  0.51,  Val Acc: 86.02%,  Time: 0:01:22 \n",
            "Iter:   2700,  Train Loss:  0.45,  Train Acc: 87.50%,  Val Loss:  0.51,  Val Acc: 85.83%,  Time: 0:01:25 \n",
            "Iter:   2800,  Train Loss:   0.6,  Train Acc: 80.47%,  Val Loss:  0.48,  Val Acc: 86.34%,  Time: 0:01:28 *\n",
            "Epoch [3/20]\n",
            "Iter:   2900,  Train Loss:  0.39,  Train Acc: 87.50%,  Val Loss:  0.53,  Val Acc: 85.48%,  Time: 0:01:31 \n",
            "Iter:   3000,  Train Loss:   0.4,  Train Acc: 86.72%,  Val Loss:  0.51,  Val Acc: 86.63%,  Time: 0:01:34 \n",
            "Iter:   3100,  Train Loss:   0.5,  Train Acc: 85.94%,  Val Loss:   0.5,  Val Acc: 86.42%,  Time: 0:01:37 \n",
            "Iter:   3200,  Train Loss:  0.59,  Train Acc: 83.59%,  Val Loss:  0.52,  Val Acc: 86.12%,  Time: 0:01:40 \n",
            "Iter:   3300,  Train Loss:   0.5,  Train Acc: 85.94%,  Val Loss:  0.47,  Val Acc: 87.50%,  Time: 0:01:44 *\n",
            "Iter:   3400,  Train Loss:  0.49,  Train Acc: 83.59%,  Val Loss:  0.49,  Val Acc: 87.43%,  Time: 0:01:47 \n",
            "Iter:   3500,  Train Loss:  0.37,  Train Acc: 85.16%,  Val Loss:  0.53,  Val Acc: 86.34%,  Time: 0:01:50 \n",
            "Iter:   3600,  Train Loss:   0.4,  Train Acc: 85.16%,  Val Loss:   0.5,  Val Acc: 86.26%,  Time: 0:01:53 \n",
            "Iter:   3700,  Train Loss:  0.63,  Train Acc: 79.69%,  Val Loss:  0.47,  Val Acc: 87.10%,  Time: 0:01:56 *\n",
            "Iter:   3800,  Train Loss:  0.43,  Train Acc: 86.72%,  Val Loss:  0.52,  Val Acc: 85.86%,  Time: 0:01:59 \n",
            "Iter:   3900,  Train Loss:  0.48,  Train Acc: 84.38%,  Val Loss:  0.48,  Val Acc: 86.83%,  Time: 0:02:02 \n",
            "Iter:   4000,  Train Loss:  0.29,  Train Acc: 92.19%,  Val Loss:   0.5,  Val Acc: 86.79%,  Time: 0:02:05 \n",
            "Iter:   4100,  Train Loss:  0.46,  Train Acc: 81.25%,  Val Loss:  0.45,  Val Acc: 86.67%,  Time: 0:02:08 *\n",
            "Iter:   4200,  Train Loss:  0.52,  Train Acc: 81.25%,  Val Loss:  0.49,  Val Acc: 87.14%,  Time: 0:02:11 \n",
            "Epoch [4/20]\n",
            "Iter:   4300,  Train Loss:  0.41,  Train Acc: 88.28%,  Val Loss:  0.43,  Val Acc: 88.28%,  Time: 0:02:15 *\n",
            "Iter:   4400,  Train Loss:  0.26,  Train Acc: 92.97%,  Val Loss:  0.46,  Val Acc: 87.66%,  Time: 0:02:18 \n",
            "Iter:   4500,  Train Loss:  0.43,  Train Acc: 85.94%,  Val Loss:  0.45,  Val Acc: 87.79%,  Time: 0:02:21 \n",
            "Iter:   4600,  Train Loss:  0.42,  Train Acc: 85.16%,  Val Loss:  0.44,  Val Acc: 88.00%,  Time: 0:02:24 \n",
            "Iter:   4700,  Train Loss:  0.58,  Train Acc: 80.47%,  Val Loss:  0.44,  Val Acc: 87.57%,  Time: 0:02:27 \n",
            "Iter:   4800,  Train Loss:  0.35,  Train Acc: 86.72%,  Val Loss:  0.47,  Val Acc: 87.78%,  Time: 0:02:30 \n",
            "Iter:   4900,  Train Loss:  0.39,  Train Acc: 85.16%,  Val Loss:  0.46,  Val Acc: 87.58%,  Time: 0:02:33 \n",
            "Iter:   5000,  Train Loss:  0.39,  Train Acc: 89.84%,  Val Loss:  0.47,  Val Acc: 87.70%,  Time: 0:02:36 \n",
            "Iter:   5100,  Train Loss:  0.51,  Train Acc: 83.59%,  Val Loss:  0.43,  Val Acc: 87.74%,  Time: 0:02:39 *\n",
            "Iter:   5200,  Train Loss:  0.55,  Train Acc: 80.47%,  Val Loss:  0.45,  Val Acc: 87.21%,  Time: 0:02:42 \n",
            "Iter:   5300,  Train Loss:  0.35,  Train Acc: 89.84%,  Val Loss:  0.49,  Val Acc: 86.89%,  Time: 0:02:45 \n",
            "Iter:   5400,  Train Loss:  0.72,  Train Acc: 81.25%,  Val Loss:  0.43,  Val Acc: 88.03%,  Time: 0:02:48 \n",
            "Iter:   5500,  Train Loss:  0.36,  Train Acc: 86.72%,  Val Loss:  0.43,  Val Acc: 87.90%,  Time: 0:02:52 \n",
            "Iter:   5600,  Train Loss:  0.43,  Train Acc: 85.16%,  Val Loss:  0.48,  Val Acc: 87.17%,  Time: 0:02:55 \n",
            "Epoch [5/20]\n",
            "Iter:   5700,  Train Loss:  0.43,  Train Acc: 84.38%,  Val Loss:  0.43,  Val Acc: 87.99%,  Time: 0:02:58 *\n",
            "Iter:   5800,  Train Loss:  0.22,  Train Acc: 91.41%,  Val Loss:  0.45,  Val Acc: 87.83%,  Time: 0:03:01 \n",
            "Iter:   5900,  Train Loss:  0.37,  Train Acc: 85.16%,  Val Loss:  0.41,  Val Acc: 88.35%,  Time: 0:03:04 *\n",
            "Iter:   6000,  Train Loss:   0.5,  Train Acc: 83.59%,  Val Loss:  0.43,  Val Acc: 88.18%,  Time: 0:03:07 \n",
            "Iter:   6100,  Train Loss:  0.48,  Train Acc: 83.59%,  Val Loss:  0.43,  Val Acc: 88.50%,  Time: 0:03:10 \n",
            "Iter:   6200,  Train Loss:  0.27,  Train Acc: 93.75%,  Val Loss:  0.43,  Val Acc: 88.59%,  Time: 0:03:13 \n",
            "Iter:   6300,  Train Loss:  0.41,  Train Acc: 85.94%,  Val Loss:  0.44,  Val Acc: 87.82%,  Time: 0:03:16 \n",
            "Iter:   6400,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.41,  Val Acc: 88.49%,  Time: 0:03:19 \n",
            "Iter:   6500,  Train Loss:  0.54,  Train Acc: 87.50%,  Val Loss:  0.44,  Val Acc: 87.93%,  Time: 0:03:22 \n",
            "Iter:   6600,  Train Loss:  0.43,  Train Acc: 88.28%,  Val Loss:  0.41,  Val Acc: 88.78%,  Time: 0:03:25 \n",
            "Iter:   6700,  Train Loss:  0.33,  Train Acc: 88.28%,  Val Loss:  0.41,  Val Acc: 88.19%,  Time: 0:03:28 \n",
            "Iter:   6800,  Train Loss:  0.37,  Train Acc: 89.06%,  Val Loss:  0.45,  Val Acc: 88.34%,  Time: 0:03:32 \n",
            "Iter:   6900,  Train Loss:  0.36,  Train Acc: 87.50%,  Val Loss:  0.42,  Val Acc: 88.18%,  Time: 0:03:35 \n",
            "Iter:   7000,  Train Loss:  0.44,  Train Acc: 85.16%,  Val Loss:  0.45,  Val Acc: 87.17%,  Time: 0:03:38 \n",
            "Epoch [6/20]\n",
            "Iter:   7100,  Train Loss:  0.35,  Train Acc: 85.94%,  Val Loss:  0.41,  Val Acc: 89.11%,  Time: 0:03:41 *\n",
            "Iter:   7200,  Train Loss:   0.4,  Train Acc: 84.38%,  Val Loss:  0.41,  Val Acc: 88.82%,  Time: 0:03:44 \n",
            "Iter:   7300,  Train Loss:  0.36,  Train Acc: 89.06%,  Val Loss:  0.39,  Val Acc: 89.20%,  Time: 0:03:47 *\n",
            "Iter:   7400,  Train Loss:  0.54,  Train Acc: 84.38%,  Val Loss:  0.43,  Val Acc: 88.53%,  Time: 0:03:50 \n",
            "Iter:   7500,  Train Loss:  0.38,  Train Acc: 87.50%,  Val Loss:  0.39,  Val Acc: 88.79%,  Time: 0:03:53 \n",
            "Iter:   7600,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.43,  Val Acc: 87.94%,  Time: 0:03:56 \n",
            "Iter:   7700,  Train Loss:  0.42,  Train Acc: 85.16%,  Val Loss:  0.42,  Val Acc: 88.60%,  Time: 0:03:59 \n",
            "Iter:   7800,  Train Loss:  0.47,  Train Acc: 83.59%,  Val Loss:   0.4,  Val Acc: 88.59%,  Time: 0:04:02 \n",
            "Iter:   7900,  Train Loss:  0.32,  Train Acc: 88.28%,  Val Loss:   0.4,  Val Acc: 88.62%,  Time: 0:04:05 \n",
            "Iter:   8000,  Train Loss:  0.42,  Train Acc: 89.06%,  Val Loss:  0.42,  Val Acc: 88.31%,  Time: 0:04:09 \n",
            "Iter:   8100,  Train Loss:  0.27,  Train Acc: 89.06%,  Val Loss:   0.4,  Val Acc: 88.62%,  Time: 0:04:12 \n",
            "Iter:   8200,  Train Loss:  0.36,  Train Acc: 88.28%,  Val Loss:  0.43,  Val Acc: 88.60%,  Time: 0:04:15 \n",
            "Iter:   8300,  Train Loss:  0.25,  Train Acc: 94.53%,  Val Loss:  0.42,  Val Acc: 88.07%,  Time: 0:04:18 \n",
            "Iter:   8400,  Train Loss:   0.6,  Train Acc: 78.91%,  Val Loss:  0.37,  Val Acc: 88.87%,  Time: 0:04:21 *\n",
            "Epoch [7/20]\n",
            "Iter:   8500,  Train Loss:  0.52,  Train Acc: 85.16%,  Val Loss:   0.4,  Val Acc: 88.86%,  Time: 0:04:24 \n",
            "Iter:   8600,  Train Loss:  0.32,  Train Acc: 88.28%,  Val Loss:  0.43,  Val Acc: 88.47%,  Time: 0:04:27 \n",
            "Iter:   8700,  Train Loss:  0.33,  Train Acc: 89.84%,  Val Loss:  0.38,  Val Acc: 89.27%,  Time: 0:04:30 \n",
            "Iter:   8800,  Train Loss:   0.4,  Train Acc: 85.94%,  Val Loss:   0.4,  Val Acc: 88.87%,  Time: 0:04:33 \n",
            "Iter:   8900,  Train Loss:  0.36,  Train Acc: 89.84%,  Val Loss:  0.39,  Val Acc: 89.33%,  Time: 0:04:36 \n",
            "Iter:   9000,  Train Loss:  0.21,  Train Acc: 89.84%,  Val Loss:  0.39,  Val Acc: 89.35%,  Time: 0:04:39 \n",
            "Iter:   9100,  Train Loss:  0.45,  Train Acc: 89.06%,  Val Loss:   0.4,  Val Acc: 89.13%,  Time: 0:04:43 \n",
            "Iter:   9200,  Train Loss:  0.47,  Train Acc: 85.16%,  Val Loss:   0.4,  Val Acc: 88.98%,  Time: 0:04:46 \n",
            "Iter:   9300,  Train Loss:  0.51,  Train Acc: 79.69%,  Val Loss:  0.37,  Val Acc: 89.13%,  Time: 0:04:49 *\n",
            "Iter:   9400,  Train Loss:  0.54,  Train Acc: 82.81%,  Val Loss:  0.41,  Val Acc: 88.70%,  Time: 0:04:52 \n",
            "Iter:   9500,  Train Loss:   0.3,  Train Acc: 90.62%,  Val Loss:  0.38,  Val Acc: 89.28%,  Time: 0:04:55 \n",
            "Iter:   9600,  Train Loss:  0.49,  Train Acc: 84.38%,  Val Loss:  0.39,  Val Acc: 89.32%,  Time: 0:04:58 \n",
            "Iter:   9700,  Train Loss:  0.33,  Train Acc: 89.06%,  Val Loss:  0.39,  Val Acc: 89.04%,  Time: 0:05:01 \n",
            "Iter:   9800,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.39,  Val Acc: 88.86%,  Time: 0:05:04 \n",
            "Epoch [8/20]\n",
            "Iter:   9900,  Train Loss:  0.58,  Train Acc: 82.03%,  Val Loss:  0.38,  Val Acc: 89.48%,  Time: 0:05:07 \n",
            "Iter:  10000,  Train Loss:  0.27,  Train Acc: 90.62%,  Val Loss:  0.41,  Val Acc: 88.88%,  Time: 0:05:10 \n",
            "Iter:  10100,  Train Loss:  0.53,  Train Acc: 83.59%,  Val Loss:   0.4,  Val Acc: 89.13%,  Time: 0:05:13 \n",
            "Iter:  10200,  Train Loss:  0.39,  Train Acc: 86.72%,  Val Loss:  0.38,  Val Acc: 89.22%,  Time: 0:05:16 \n",
            "Iter:  10300,  Train Loss:  0.39,  Train Acc: 89.84%,  Val Loss:  0.38,  Val Acc: 89.54%,  Time: 0:05:19 \n",
            "Iter:  10400,  Train Loss:  0.34,  Train Acc: 86.72%,  Val Loss:  0.38,  Val Acc: 89.16%,  Time: 0:05:22 \n",
            "Iter:  10500,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:   0.4,  Val Acc: 89.18%,  Time: 0:05:26 \n",
            "Iter:  10600,  Train Loss:  0.39,  Train Acc: 86.72%,  Val Loss:  0.39,  Val Acc: 89.29%,  Time: 0:05:29 \n",
            "Iter:  10700,  Train Loss:  0.28,  Train Acc: 91.41%,  Val Loss:  0.39,  Val Acc: 88.76%,  Time: 0:05:32 \n",
            "Iter:  10800,  Train Loss:  0.42,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 89.18%,  Time: 0:05:35 \n",
            "Iter:  10900,  Train Loss:  0.48,  Train Acc: 85.94%,  Val Loss:  0.37,  Val Acc: 89.39%,  Time: 0:05:38 \n",
            "Iter:  11000,  Train Loss:  0.36,  Train Acc: 88.28%,  Val Loss:  0.39,  Val Acc: 89.01%,  Time: 0:05:41 \n",
            "Iter:  11100,  Train Loss:  0.37,  Train Acc: 90.62%,  Val Loss:  0.38,  Val Acc: 88.99%,  Time: 0:05:44 \n",
            "Iter:  11200,  Train Loss:  0.42,  Train Acc: 83.59%,  Val Loss:  0.39,  Val Acc: 89.17%,  Time: 0:05:47 \n",
            "Epoch [9/20]\n",
            "Iter:  11300,  Train Loss:  0.38,  Train Acc: 87.50%,  Val Loss:  0.39,  Val Acc: 89.43%,  Time: 0:05:50 \n",
            "No optimization for a long time, auto-stopping...\n",
            "Test Loss:  0.36,  Test Acc: 89.14%\n",
            "Precision, Recall and F1-Score...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      finance     0.8542    0.8850    0.8694      1000\n",
            "       realty     0.8971    0.9240    0.9103      1000\n",
            "       stocks     0.8554    0.7570    0.8032      1000\n",
            "    education     0.9171    0.9510    0.9337      1000\n",
            "      science     0.8426    0.7920    0.8165      1000\n",
            "      society     0.9195    0.8800    0.8993      1000\n",
            "     politics     0.8426    0.8940    0.8675      1000\n",
            "       sports     0.9867    0.9620    0.9742      1000\n",
            "         game     0.9085    0.9140    0.9113      1000\n",
            "entertainment     0.8900    0.9550    0.9214      1000\n",
            "\n",
            "     accuracy                         0.8914     10000\n",
            "    macro avg     0.8914    0.8914    0.8907     10000\n",
            " weighted avg     0.8914    0.8914    0.8907     10000\n",
            "\n",
            "Confusion Matrix...\n",
            "[[885  27  44   9  14   2  12   1   3   3]\n",
            " [ 14 924  19   4   6  11   6   1   1  14]\n",
            " [ 91  30 757   2  47   0  51   1  14   7]\n",
            " [  3   4   1 951   6   8   7   1   5  14]\n",
            " [ 16  11  33  12 792  21  36   1  47  31]\n",
            " [  4  19   2  28   7 880  38   0   5  17]\n",
            " [ 14   6  18  15   9  23 894   1   5  15]\n",
            " [  0   2   2   4   6   3   7 962   0  14]\n",
            " [  4   4   8   7  45   5   8   2 914   3]\n",
            " [  5   3   1   5   8   4   2   5  12 955]]\n",
            "Time usage: 0:00:01\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
